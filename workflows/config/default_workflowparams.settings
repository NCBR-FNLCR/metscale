from snakemake.utils import update_config

config_default = {

    # the name of the directory where everything is being stored
    "data_dir" : "data",
    "sing_dir" : "/tmp",
    "assembly_dir" : "assembly",

    "read_filtering" : {
        # 
        "read_patterns" : {
            #
            # filename pattern for pre-trimmed reads
            "pre_trimming_pattern"  : "{sample}_{direction}_reads",
            #
            #shakya glob pattern
            "pre_trimming_glob_pattern"  : "*_1_reads.fq.gz",
            # Illumina glob pattern
            #"pre_trimming_glob_pattern"  : "*_S*_L*_R1_001.fastq.gz",
            #
            # file pattern to locate reverse end string
            # we are searching from the right of the filename for the unique file pattern that is locates the reverse reads
            # for the shakya dataset that is 1_ for reverse_pe_pattern_search (forward read) 2_ for reverse_pe_pattern_replace (reverse read)
            # for Illumina that would be R1 for reverse_pe_pattern_search(forward read) R2 for reverse_pe_pattern_replace (reverse read)
            "reverse_pe_pattern_search"  : "1_",
            "reverse_pe_pattern_replace" : "2_",
            #
            # filename pattern for post-trimmed reads
            "post_trimming_pattern" : "{sample}_trim{qual}_{direction}",
            #
            # number of threads to use.
            "threads" : 2
        },
        "quality_trimming" : {
            # 
            # suffix for quality trimming files (replaces file extension)
            "trim_suffix" : "se",
            # use for shakya dataset with .fq.gz file extensions 
            "sample_file_ext" : ".fq.gz"
            # use the following for Illumina naming conventions with .fastq.gz file extensions
            #"sample_file_ext" : ".fastq.gz"
        },
        "direction_labels" : {
            "forward" : "1",
            "reverse" : "2"
        },
        "quality_assessment" : {
            #
            # optional, modifiers for the .fq.gz --> .zip --> results workflow
            "fastqc_suffix": "fastqc",
        },
        "multiqc" :{
            # multiqc output dir pattern
            "multiqc_pattern_report" : "{sample}_fastqc_multiqc_report_data",
            # multiqc output file
            "multiqc_pattern_report_file" : "{sample}_fastqc_multiqc_report",
            # multiqc input file pattern
            "multiqc_input_pattern" : "{sample}_trim{qual}_{direction}_fastqc.zip",
        }, 
        # Set the read adapter file
        "adapter_file" : {
            # 
            # name and URL for the sequencer adapter file
            "name" : "adapters_combined_256_unique.fasta",
            "url"  : "https://raw.githubusercontent.com/signaturescience/metagenomics/master/resources/adapters_combined_256_unique.fasta",
            "threads" : 4
        },
        "interleaving" : {
            # 
            # output pattern for khmer interleave reads
            "interleave_output_pattern" : "{sample}_trim{qual}_interleaved_reads.fq.gz",
        },
        "subsample_interleaving" : {
             #
             # output of subset percentage (10 = 10%, don't use zero!)
             "percent" : 10,
             "subsample_output_pattern" : "{sample}_trim{qual}_subset{percent}_interleaved_reads.fq.gz",
             "max_reads" : 100000000
        },
        "split_interleaved_reads" : {
            #
            # output file pattern
            "split_interleaved_output_pattern" : "{sample}_trim{qual}_subset{percent}_{direction}.fq.gz"
        },
        "count_unique_reads" : {
            #
            # input file pattern. Right now set to the output from interleaving
            "input_pattern" : "{sample}_trim{qual}_interleaved_reads.fq.gz",
            # input pattern from the subsample interleave
            #"input_pattern" : "{sample}_trim{qual}_subset_interleaved_reads.fq.gz",
            # output file pattern.
            "output_pattern" : "{sample}_trim{qual}_interleaved_uniqueK{kmers}.txt",
        },
        "convert_fastq_fasta" : {
            #
            # input fastq file
            "input_pattern" : "{file}.fq.gz",
            "output_pattern" : "{file}.fa",
            "output_dir" : "fasta"
        },
    },

    "assembly" : {
        #TODO break into smaller sections like the other areas
        "assembly_patterns" : {
            # 
            # general assembler output filename pattern/input for quast
            "assembly_pattern" : "{sample}_trim{qual}.{assembler}.contigs.fa",
            #
            # filename pattern for metaspades output and threads to run
            "metaspades_pattern" : "{sample}_trim{qual}.metaspades.contigs.fa",
            "metaspades_threads" : 8,
            #
            # filename pattern for megahit output amd threads to run
            "megahit_pattern" : "{sample}_trim{qual}.megahit.contigs.fa",
            "megahit_threads" : 8,
            #
            # filename pattern for spades output and threads to run. Note I use the string kmer to do a replace with the kmer values listed.
            "spades_pattern" : "{sample}_trim{qual}_kkmer.spades.contigs.fa",
            "kmer" : [21, 33, 55],
            "spades_threads" : 8, 
            # 
            # filename pattern for plasmidspades output and threads to run
            "plasmidspades_pattern" : "{sample}_trim{qual}.plasmidspades.contigs.fa",
            "plasmidspades_threads" : 8,           
            #
            #
            # quast output filename pattern and threads to run
            "quast_pattern" : "{sample}_trim{qual}.{assembler}_quast/",
            "quast_threads" : 4,
            #
            #  metaquast output file pattern and threads to run
            "metaquast_pattern" : "{sample}_trim{qual}.{assembler}_metaquast/",
            "metaquast_threads" : 4,
            "metaquast_ref" :  "GCF_000008565.1_ASM856v1_genomic.fna.gz",
            "metaquast_output_multiqc_input_file" : "report.html",
            #
            # multiqc output dir pattern
            "assembly_multiqc_pattern_report" : "{sample}.{assembler}_multiqc_report",
            # multiqc input file. Taken from quast output file.
            "quast_output_multiqc_input_file" : "report.tsv",
            # multiqc output file
            "multiqc_pattern_report_file" : "{sample}.{assembler}_multiqc_fastqc_report",
            #
            # quast with SPAdes output file pattern
            "quast_spades_pattern" : "{sample}_trim{qual}.spades_quast/",
            "quast_spades_threads" : 4,
            "quast_spades_ref" : "GCF_000008565.1_ASM856v1_genomic.fna.gz",
            # 
            # quast with plasmidSPAdes output file pattern
            "quast_plasmidspades_pattern" : "{sample}_trim{qual}.plasmidspades_quast",
            "quast_plasmidspades_threads" : 4,
            "quast_plasmidspades_ref" : "GCF_000008565.1_ASM856v1_genomic.fna.gz",
            #


        }
    },

    "comparison" : {
        "compute_read_signatures" : {
            #
            # specify scale and k values for computing signatures
            "scale"         : 10000,
            "kvalues"       : [21,31,51],
            "qual"          : ["2","30"],
            #
            # the signature file suffixes specified below 
            # should match the scale and k values above.
            #
            # sig_suffix is used to replace .fq.gz with a signature suffix
            "sig_suffix"    : "_scaled{scale}.k{kvalues}.sig", 
            #
            # merge_suffix is used to replace .fq.gz with a merge file suffix
             "merge_suffix"  : "_merge_scaled{scale}.k{kvalues}.fq.gz"
        },
        "compare_read_signatures" : {
            #
            # the samples and quality variables are used in expand() to form filenames
            # 
            # csv_out is the single output file containing comparisons of all input files.
            # {kvalue_read} is replaced with the k value used in the comparison.
            # note that the file prefix does not need to be/should not be modified.

            "csv_out" : "{sample}_trim{qual}_read_comparison.k{kvalue_read}.csv"
        },
        "compute_assembly_signatures" : {
            # 
            # specify scale and k values for computing signatures
            "scale"         : 10000,
            "kvalues"       : [21,31,51],
            "qual"          : ["2","30"],
            #
            # sig_suffix is used to replace .fq.gz with a signature suffix
            "sig_suffix" : "_scaled{scale}.k{kvalues}.sig",
            #
            # merge_suffix is used to replace .fq.gz with a merge file suffix
            "merge_suffix"  : "_scaled10k.k21_31_51.fq.gz"
        },
        "compare_assembly_signatures" : {
            #
            # the samples and quality variables are used in expand() to form filenames
            "assembler" : ["megahit","metaspades"],
            #
            # csv_out is the single output file containing comparisons of all input files
            # {kvalue} is replaced with the k value used in the comparison
            "csv_out"   : "{sample}_trim{qual}_assembly_comparison.k{kvalue_assembly}.csv"
        },
        "compare_read_assembly_signatures" : {
            #
            # the samples, quality, assembler variables are used in expand() to form filenames
            "assembler" : ["megahit","metaspades"],
            #
            # k values are passed to sourmash compare
            "kvalues"   : [21, 31, 51],
            #
            # csv_out is the single output file containing
            # comparison results among all of the above files.
            "csv_out"   : "{sample}_read_assembly_comparison.k{kvalue_read_assembly}.csv"
        }
    },

    "taxonomic_classification" : {
        "filter_taxa" : {
            #
            # percent threshold for taxa filtering
            "pct_threshold" : 1
        },
        "kaiju" : {
            "dmp1" : "nodes.dmp",
            "dmp2" : "names.dmp",
            "fmi"  : "kaiju_db_nr_euk.fmi",
            "tar"  : "kaiju_index_nr_euk.tgz",
            "url"  : "http://kaiju.binf.ku.dk/database",
            #"url"  : "https://s3.amazonaws.com/dahak-project-ucdavis/kaiju",
            "out"  : "{sample}_trim{qual}.kaiju.out",
            "contig_out" : "{sample}_trim{qual}_{assembler}.kaiju.out",
            "threads" : 8
        },
        "kaiju_report" : {
            #
            # specify the taxonomic rank for kaiju report to use
            "taxonomic_rank" : "genus",
            #
            # if the user asks for a kaiju report with filtered taxa,
            # use this as the percent threshold
            "pct_threshold"  : 1
        },
        "contigs_kaiju_report" : {
            "contigs_taxonomic_rank" : "genus",
            "contigs_pct_threshold" : 1
        },
        "sourmash" : { 
            #
            # URL base for SBT tree
            "sbturl"  : "s3-us-west-1.amazonaws.com/spacegraphcats.ucdavis.edu",
            # 
            # name of SBT tar file
            "sbttar"  : "microbe-{database}-sbt-k{kvalue}-2017.05.09.tar.gz",
            #
            # name of SBT file when unpacked
            "sbtunpack" : "{database}-k{kvalue}.sbt.json",
            #
            # names of valid databases
            "databases" : ["genbank","refseq"],
            #
            # output csv name for sourmash gather procedure
            "gather_csv_out"        : "{sample}_trim{qual}_k{kvalue}.gather_output.csv",
            "gather_unassigned_out" : "{sample}_trim{qual}_k{kvalue}.gather_unassigned.csv",
            "gather_matches_out"    : "{sample}_trim{qual}_k{kvalue}.gather_matches.csv"
        },
        "visualize_krona" : {
            #
            # .summary will be replaced with .html for the final report
            "input_summary"  : "{sample}_trim{qual}_kaiju_output.summary",
        },
        "kraken2" : {
            #
            # kraken2 output results
            "kraken2_output" : "{sample}_trim{qual}_kraken2_{db}_confidence{conf}.report",
            "threads" : 6,
            "unclass_out" : "{sample}_trim{qual}_kraken2_unclassified_{db}_confidence{conf}#.fq.gz",
            "class_out" : "{sample}_trim{qual}_kraken2_classified_{db}_confidence{conf}#.fq.gz",
            "report" : "{sample}_trim{qual}_kraken2_{db}_confidence{conf}.report"
        },
        "krakenuniq" : {
            #
            # krakenuniq output results
            "krakenuniq_output" : "{sample}_trim{qual}_krakenuniq_{db}_hll{hll_prec}_out",
            "threads" : 6,
            "unclass_out" : "{sample}_trim{qual}_krakenuniq_{db}_hll{hll_prec}_unclassified",
            "class_out" : "{sample}_trim{qual}_krakenuniq_{db}_hll{hll_prec}_classified",
            "report" : "{sample}_trim{qual}_krakenuniq_{db}_hll{hll_prec}_report"
        },
        "bracken" : {
            #bracken output filename
            "bracken_output" : "_bracken_db-{bdb}_r-{read_length}_l-{level}_t-{threshold}",
        }
    },

    "functional_inference" : {
        # params for functional inference workflow
        "prokka_with_megahit" : {  
            "outdir_pattern" : "{sample}_trim{qual}_megahit.prokka_annotation",
            "input_pattern" : "{sample}_trim{qual}.megahit.contigs.fa",
            "prefix_pattern" : "{sample}_trim{qual}_megahit",
            "input_db" : " ",
            "threads" : 8
        },
        "prokka_with_metaspades" : {
            "outdir_pattern" : "{sample}_trim{qual}_metaspades.prokka_annotation",
            "input_pattern" : "{sample}_trim{qual}.metaspades.contigs.fa",
            "prefix_pattern" : "{sample}_trim{qual}_metaspades",
            "input_db" : " ",
            "threads" : 8
        },
        "prokka_with_spades" : {
            "outdir_pattern" : "{sample}_trim{qual}_spades.prokka_annotation",
            "input_pattern" : "{sample}_trim{qual}.spades.contigs.fa",
            "prefix_pattern" : "{sample}_trim{qual}_spades",
            "input_db" : " ",
            "threads" : 8
        },
        "abricate_with_metaspades" : {
            "output_pattern" : "{sample}_trim{qual}_metaspades.abricate_{db}.csv",
            "input_pattern" : "{sample}_trim{qual}.metaspades.contigs.fa",
            # set by default to use internal DB's
            "db_dir" : "/opt/abricate/db/"
            #use external dirs
            #"db_dir" : "sing_dir"
        },
        "abricate_with_megahit" : {
            "output_pattern" : "{sample}_trim{qual}_megahit.abricate_{db}.csv",
            "input_pattern" : "{sample}_trim{qual}.megahit.contigs.fa",
            # set by default to use internal DB's
            "db_dir" : "/opt/abricate/db/"
            #use external dirs
            #"db_dir" : "sing_dir"
        },
        "direction_labels" : {
            "forward" : "1",
            "reverse" : "2"
        },
        # input param for srst2 is pulled from read filtering post_trimming_pattern
        "srst2" : {
            "threads" : 4,
            "output_pattern" : "{sample}_trim{qual}_{db}.srst2",
        }
    },

    "post_processing" : {
        # params for the post processing workflow
        "move_samples_to_dir" : {
            # file pattern to move files to in post processing
            "output_pattern" : "{sample}_finished"
        },
    },

    # This is for airgapped systems or other systems that need to use only local biocontainers.
    # Note: don"t include http:// or https://
    "biocontainers" : {
        "osf" : {
            "use_local" : False,
            "quayurl" : "quay.io/centerforopenscience/osf",
            "version" : "master"
        },
        "trimmomatic" : {
            "use_local" : True,
            "filename" : "trimmomatic_0.36--5.sif",
            "quayurl" : "quay.io/biocontainers/trimmomatic",
            "location" : "../container_images/",
            "version" : "0.36--5"
        },
        "fastqc" : {
            "use_local" : True,
            "filename" : "fastqc_0.11.7--pl5.22.0_2.sif",
            "quayurl" : "quay.io/biocontainers/fastqc",
            "location" : "../container_images/",
            "version" : "0.11.7--pl5.22.0_2"
        },
        "multiqc" : {
            "use_local" : True,
            "filename" : "multiqc_1.4--py35_0.sif",
            "quayurl" : "quay.io/biocontainers/multiqc",
            "location" : "../container_images/",
            "version" : "1.4--py35_0"
        },
        "khmer" : {
            "use_local" : True,
            "filename" : "khmer_2.1--py35_0.sif",
            "quayurl" : "quay.io/biocontainers/khmer",
            "location" : "../container_images/",
            "version" : "2.1--py35_0"
        },
        "megahit" : {
            "use_local" : True,
            "filename" : "megahit_1.1.2--py35_0.sif",
            "quayurl" : "quay.io/biocontainers/megahit",
            "location" : "../container_images/",
            "version" : "1.1.2--py35_0"
        },
        "spades" : {
            "use_local" : True,
            "filename" : "spades_3.11.1--py36_zlib1.2.8_0.sif",
            "location" : "../container_images/",
            "quayurl" : "quay.io/biocontainers/spades",
            "version" : "3.11.1--py36_zlib1.2.8_0"
        },
        "quast" : {
            "use_local" : True,
            "filename" : "quast_5.0.2--py27pl526ha92aebf_0.sif",
            "quayurl" : "quay.io/biocontainers/quast",
            "location" : "../container_images/",
            "version" : "py27pl526ha92aebf_0"
        },
        "sourmash" : {
            "use_local" : True,
            "filename" : "sourmash_2.1.0--py27he1b5a44_0.sif",
            "quayurl" : "quay.io/biocontainers/sourmash",
            "location" : "../container_images/",
            "version" : "2.1.0--py27he1b5a44_0"
        },
        "sourmash_compare" : {
            "use_local" : True,
            "filename" : "sourmash_2.1.0--py27he1b5a44_0.sif",
            "quayurl" : "quay.io/biocontainers/sourmash",
            "location" : "../container_images/",
            "version" : "2.1.0--py27he1b5a44_0"
        },
        "kaiju" : {
            "use_local" : True,
            "filename" : "kaiju_1.6.1--pl5.22.0_0.sif",
            "location" : "../container_images/",
            "quayurl" : "quay.io/biocontainers/kaiju",
            "version" : "1.6.1--pl5.22.0_0"
        },
        "krona" : {
            "use_local" : True,
            "filename" : "krona_2.7--pl5.22.0_1.sif",
            "location" : "../container_images/",
            "quayurl" : "quay.io/biocontainers/krona",
            "version" : "2.7--pl5.22.0_1"
        },
        "kraken2" : {
            "use_local" : True,
            "filename" : "kraken2_2.0.8_beta--pl526h6bb024c_0.sif",
            "location" : "../container_images/",
            "quayurl" : "quay.io/biocontainers/kraken2",
            "version" : "2.0.8_beta--pl526h6bb024c_0"
        },
        "bracken" : {
            "use_local" : True,
            "filename" : "bracken_2.2--py27h2d50403_1.sif",
            "location" : "../container_images/",
            "quayurl" : "quay.io/biocontainers/bracken",
            "version" : "2.2--py27h2d50403_1"        
        },
        "krakenuniq" : {
            "use_local" : True,
            "filename" : "krakenuniq_0.5.8--pl526he860b03_0.sif",
            "location" : "../container_images/",
            "quayurl" : "quay.io/biocontainers/krakenuniq",
            "version" : "0.5.8--pl526he860b03_0"
        },
        "prokka" : {
            "use_local" : True,
            "filename" : "prokka_1.13.3-01.sif",
            "location" : "../container_images/",
            "quayurl" : "ummidock/prokka",
            "version" : "1.13.3-01"        
        },
        "abricate" : {
            "use_local" : True,
            "filename" : "abricate_latest.sif",
            "location" : "../container_images/",
            "quayurl" : "thanhleviet/abricate",
            "version" : "latest"         
        },
        "srst2" : {
            "use_local" : True,
            "filename" : "srst2_0.2.0--py27_2.sif",
            "location" : "../container_images/",
            "version" : "0.2.0--py27_2",
            "quayurl" : "quay.io/biocontainers/srst2"
        }
    }

}

update_config(config_default, config)
config = config_default
