'''
Author: Phillip Brooks, Charles Reid
Affiliation: UC Davis Lab for Data Intensive Biology
Objective: Use sourmash to compute signatures and taxonomically classify the components of a metagenome by comparing hashes in our dataset to hashes in a sequence bloom tree (SBT) representing genomes.
Date: 2018-06-08
Documentation: docs/workflow_taxclass.md
'''

from common.utils  import container_image_is_external, container_image_name
from os.path import join, isfile, dirname
import os, re
from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
HTTP = HTTPRemoteProvider()



############################################
# Taxonomic Classification: default config

data_dir = config['data_dir']
biocontainers = config['biocontainers']
taxclass = config['taxonomic_classification']


###################################
# Taxonomic Classification: build rules

# Skip to the very end of the file 
# to see the high-level build rules
# that trigger cascades of workflow
# tasks.


############################################
# Taxonomic Classification: sourmash SBT

sourmash_sbt_tar = taxclass['sourmash']['sbttar']
download_sourmash_sbt_input = HTTP.remote(taxclass['sourmash']['sbturl'] + "/" + sourmash_sbt_tar)
download_sourmash_sbt_output = join(data_dir,taxclass['sourmash']['sbttar'])
unpack_sourmash_sbt_input = download_sourmash_sbt_output
unpack_sourmash_sbt_output = join(data_dir,taxclass['sourmash']['sbtunpack'])

def unpack_sourmash_sbt_tar(wildcards):
    """Perform wildcard substitution to obtain name of sourmash SBT tar files."""
    # input/output can have {variables} in them, but we need to do
    # wildcard substiution before we can actually use these to
    # assemble commands.
    return unpack_sourmash_sbt_input.format(**wildcards)


rule download_sourmash_sbts:
    """
    Download the sourmash SBTs
    """
    input:
        download_sourmash_sbt_input
    output:
        unpack_sourmash_sbt_input
    message: 
        '''--- Downloading sourmash SBTs.'''
    params:
        tar_wc = unpack_sourmash_sbt_tar
    shell:
        '''
        wget -O {params.tar_wc} {input}
        '''
  


rule unpack_sourmash_sbts:
    """
    Unpack the sourmash SBTs
    """
    input:
        unpack_sourmash_sbt_input
    output:
        unpack_sourmash_sbt_output
    message: 
        '''--- Unpacking sourmash SBTs.'''
    params:
        tar_wc = unpack_sourmash_sbt_tar
    shell:
        '''
        tar -xzf {params.tar_wc} -C {data_dir} && rm -f {params.tar_wc}
        '''


############################################
# Taxonomic Classification: gather signatures

# See comparison workflow,
# which contains rules for
# calculating read signatures
# using sourmash compute.

all_unpacked_sbts = expand(taxclass['sourmash']['sbtunpack'],
                            kvalue = '{kvalue}',
                            database = taxclass['sourmash']['databases'])
all_unpacked_sbts = [join(data_dir, j) for j in all_unpacked_sbts]

gather_csv        = join(data_dir, taxclass['sourmash']['gather_csv_out'])
gather_unassigned = join(data_dir, taxclass['sourmash']['gather_unassigned_out'])
gather_matches    = join(data_dir, taxclass['sourmash']['gather_matches_out'])

sourmash_image = container_image_name(biocontainers, 'sourmash')


def gather_csv_wc_f(wildcards):
    return gather_csv.format(**wildcards)

def gather_unassigned_wc_f(wildcards):
    return gather_unassigned.format(**wildcards)

def gather_matches_wc_f(wildcards):
    return gather_matches.format(**wildcards)


rule gather_compare_signatures:
    """
    Gather and compare signatures using sourmash gather
    """
    input:
        compute_read_sig_output,
        all_unpacked_sbts
    output:
        gather_csv,
        gather_unassigned,
        gather_matches
    singularity:
        sourmash_image
    params:
        gather_csv_wc = gather_csv_wc_f,
        gather_unassigned_wc = gather_unassigned_wc_f,
        gather_matches_wc = gather_matches_wc_f
    shell:
        'sourmash gather '
        '-k {wildcards.kvalue} '
        '{input} '
        '-o {params.gather_csv_wc} '
        '--output-unassigned {params.gather_unassigned_wc} '
        '--save-matches {params.gather_matches_wc} '


############################################
# Taxonomic Classification: download kaiju databases

# output file paths
kaiju_dmp1   = join(data_dir, taxclass['kaiju']['dmp1'])
kaiju_dmp2   = join(data_dir, taxclass['kaiju']['dmp2'])
kaiju_fmi    = join(data_dir, taxclass['kaiju']['fmi'])
kaiju_dmp1_sing   = join(sing_dir, taxclass['kaiju']['dmp1'])
kaiju_dmp2_sing   = join(sing_dir, taxclass['kaiju']['dmp2'])
kaiju_fmi_sing    = join(sing_dir, taxclass['kaiju']['fmi'])

kaiju_target = join(data_dir, taxclass['kaiju']['tar'])
kaiju_target_sing = join(sing_dir, taxclass['kaiju']['tar'])

kaiju_tar    = taxclass['kaiju']['tar']
kaiju_url    = taxclass['kaiju']['url']

unpack_kaiju_input = HTTP.remote(kaiju_url,allow_redirects=True)
#unpack_kaiju_input = HTTP.remote(kaiju_url+"/"+kaiju_tar, allow_redirects=True)
unpack_kaiju_output = [kaiju_dmp1, kaiju_dmp2, kaiju_fmi]


rule download_kaijudb:
    """
    Download the kaiju database
    (this is a large file and may take up to 30 minutes)
    """
    #input:
    #    unpack_kaiju_input
    output:
        kaiju_target
    message: 
        '''--- Downloading kaiju database.'''
    shell:
        '''
        wget -O {kaiju_target} "{kaiju_url}/{kaiju_tar}"
        '''

rule unpack_kaijudb:
    """
    Unpack the kaiju database
    """
    input:
        kaiju_target
    output:
        unpack_kaiju_output
    message: 
        '''--- Unpacking kaiju database.'''
    shell:
        '''
        tar -xzf {kaiju_target} -C {data_dir} && rm -f {kaiju_target}
        '''


############################################
# Taxonomic Classification: run kaiju

fq_fwd = join(data_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']).format(
                sample = '{sample}',
                qual = '{qual}',
                direction = readfilt['direction_labels']['forward']))
fq_rev = join(data_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']).format(
                sample = '{sample}',
                qual = '{qual}',
                direction = readfilt['direction_labels']['reverse']))

fq_fwd_sing = join(sing_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']).format(
                sample = '{sample}',
                qual = '{qual}',
                direction = readfilt['direction_labels']['forward']))
fq_rev_sing = join(sing_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']).format(
                sample = '{sample}',
                qual = '{qual}',
                direction = readfilt['direction_labels']['reverse']))

run_kaiju_input_files = [kaiju_dmp1, kaiju_dmp2, kaiju_fmi]
run_kaiju_input_files += [fq_fwd, fq_rev]
run_kaiju_output_file = join(data_dir, taxclass['kaiju']['out'])
run_kaiju_output_file_sing = join(sing_dir, taxclass['kaiju']['out'])
tax_class_kaiju_threads = taxclass['kaiju']['threads']

kaiju_image = container_image_name(biocontainers, 'kaiju')


def run_kaiju_fq_fwd(wildcards):
    # Get forward fq files
    fq_fwd_wc = fq_fwd_sing.format(**wildcards)
    return fq_fwd_wc

def run_kaiju_fq_rev(wildcards):
    # Get reverse fq files
    fq_rev_wc = fq_rev_sing.format(**wildcards)
    return fq_rev_wc

def run_kaiju_output(wildcards):
    # Get output
    run_kaiju_output_file_wc = run_kaiju_output_file_sing.format(**wildcards)
    return run_kaiju_output_file_wc


rule run_kaiju:
    """
    Run kaiju after downloading and unpacking the kaiju database. 
    """
    input:
        run_kaiju_input_files
    output:
        run_kaiju_output_file
    message: 
        '''--- Running kaiju.'''
    singularity: 
        kaiju_image
    threads:
        tax_class_kaiju_threads
    params:
        fq_fwd_wc = run_kaiju_fq_fwd,
        fq_rev_wc = run_kaiju_fq_rev,
        run_kaiju_output_file_wc = run_kaiju_output
    shell:
        'kaiju '
        '-x '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-f /{kaiju_fmi_sing} '
        '-i /{params.fq_fwd_wc} '
        '-j /{params.fq_rev_wc} '
        '-o /{params.run_kaiju_output_file_wc} '
        '-z {threads}'




############################################
# Taxonomic Classification: run kaiju on contigs
run_kaiju_contig_input_files = [kaiju_dmp1, kaiju_dmp2, kaiju_fmi]
run_kaiju_contig_input_files.append(join(data_dir, assembly['assembly_patterns']['assembly_pattern']))

run_kaiju_contig_input_files_sing = join(sing_dir, assembly['assembly_patterns']['assembly_pattern'])


run_kaiju_contigs_output_file = join(data_dir, taxclass['kaiju']['contig_out'])
run_kaiju_contigs_output_file_sing = join(sing_dir, taxclass['kaiju']['contig_out'])

def run_contigs_output_sing(wildcards):
    kaiju_output_sing = run_kaiju_contigs_output_file_sing.format(**wildcards)
    return kaiju_output_sing

def run_contigs_input_sing(wildcards):
    kaiju_input_sing = run_kaiju_contig_input_files_sing.format(**wildcards)
    return kaiju_input_sing

tax_class_contigs_kaiju_threads = taxclass['kaiju']['threads']

rule run_contigs_kaiju:
    """
    Run kaiju after downloading and unpacking the kaiju database with contigs. 
    """
    input:
        run_kaiju_contig_input_files
    output:
        run_kaiju_contigs_output_file
    message: 
        '''--- Running kaiju with contigs.'''
    singularity: 
        kaiju_image
    threads:
        tax_class_contigs_kaiju_threads
    params:
        contig_wc = run_contigs_input_sing,
        run_contigs_kaiju_output_file_wc = run_contigs_output_sing
    shell:
        'kaiju '
        '-x '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-f /{kaiju_fmi_sing} '
        '-i /{params.contig_wc} '
        '-o /{params.run_contigs_kaiju_output_file_wc} '
        '-z {threads}'


############################################
# Taxonomic Classification: kaiju format to krona format

tax_rank = taxclass['kaiju_report']['taxonomic_rank']

# name of kaiju output determines name of kaiju2krona input
kaiju2krona_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_output_file]

# One approach is to let the user set this.
# But here, we just take care of it for them.
kaiju2krona_output_file = re.sub(r'\.out','.kaiju_out_krona',run_kaiju_output_file)
kaiju2krona_output_file_sing = re.sub(r'\.out','.kaiju_out_krona',run_kaiju_output_file_sing)

kaiju_image = container_image_name(biocontainers, 'kaiju')

def kaiju2krona_input_func(wildcards):
    # Return the kaiju2krona input file names
    kaiju2krona_input_wc = run_kaiju_output_file_sing.format(**wildcards)
    return kaiju2krona_input_wc

def kaiju2krona_output_func(wildcards):
    # Return the kaij2krona input file names
    kaiju2krona_output_wc = kaiju2krona_output_file_sing.format(**wildcards)
    return kaiju2krona_output_wc


rule kaiju2krona:
    """
    Convert kaiju results to a file format readable by krona
    """
    input:
        kaiju2krona_input_files
    output:
        kaiju2krona_output_file
    message: 
        '''--- Running kaiju2krona to convert kaiju results to krona format.'''
    singularity:
        kaiju_image
    params:
        kaiju2krona_input_wc = kaiju2krona_input_func,
        kaiju2krona_output_wc = kaiju2krona_output_func
    shell:
        'kaiju2krona '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju2krona_input_wc} '
        '-o /{params.kaiju2krona_output_wc} '


############################################
# Taxonomic Classification: kaiju add taxon names

taxon_names_contigs_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_contigs_output_file]
taxon_names_contigs_output_file = re.sub(r'\.out', '_names.out', run_kaiju_contigs_output_file)
taxon_names_contigs_output_file_sing = re.sub(r'\.out', '_names.out', run_kaiju_contigs_output_file_sing)


def taxon_names_contigs_input_file_sub(wildcards):
    """
    Wildcard substitution for (one of the) input files to the addTaxonNames
    command. The other input files do not have wildcards, so it's only
    the run_kaiju_output_file (which is the input to add taxon names) 
    that requires wildcard substitution.
    """
    return run_kaiju_contigs_output_file_sing.format(**wildcards)

def taxon_names_contigs_output_file_sub(wildcards):
    """
    Wildcard substitution of taxon names output.
    The taxon names output is just the kaiju output name,
    but replacing .out with .names.out.
    """
    return taxon_names_contigs_output_file_sing.format(**wildcards)


rule add_taxon_names_2_contigs:
    """
    Use kaiju to add taxon names to contigs
    """
    input:
        taxon_names_contigs_input_files
    output:
        taxon_names_contigs_output_file
    message: 
        '''--- Running kaiju to add taxon names to contigs.'''
    singularity:
        kaiju_image
    params:
        taxon_names_contigs_input_file_wc  = taxon_names_contigs_input_file_sub,
        taxon_names_contigs_output_file_wc = taxon_names_contigs_output_file_sub
    shell:
        'addTaxonNames '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-u '
        '-p '
        '-i {params.taxon_names_contigs_input_file_wc} '
        '-o {params.taxon_names_contigs_output_file_wc} '



############################################
# Taxonomic Classification: kaiju add taxon names from contigs

taxon_names_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_output_file]
taxon_names_output_file = re.sub(r'\.out', '_names.out', run_kaiju_output_file)
taxon_names_output_file_sing = re.sub(r'\.out', '_names.out', run_kaiju_output_file_sing)


def taxon_names_input_file_sub(wildcards):
    """
    Wildcard substitution for (one of the) input files to the addTaxonNames
    command. The other input files do not have wildcards, so it's only
    the run_kaiju_output_file (which is the input to add taxon names) 
    that requires wildcard substitution.
    """
    return run_kaiju_output_file_sing.format(**wildcards)

def taxon_names_output_file_sub(wildcards):
    """
    Wildcard substitution of taxon names output.
    The taxon names output is just the kaiju output name,
    but replacing .out with .names.out.
    """
    return taxon_names_output_file_sing.format(**wildcards)


rule add_taxon_names:
    """
    Use kaiju to add taxon names
    """
    input:
        taxon_names_input_files
    output:
        taxon_names_output_file
    message: 
        '''--- Running kaiju to add taxon names.'''
    singularity:
        kaiju_image
    params:
        taxon_names_input_file_wc  = taxon_names_input_file_sub,
        taxon_names_output_file_wc = taxon_names_output_file_sub
    shell:
        'addTaxonNames '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-u '
        '-p '
        '-i {params.taxon_names_input_file_wc} '
        '-o {params.taxon_names_output_file_wc} '



############################################
# Taxonomic Classification:  kaiju species summary 
kaiju_summary_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_output_file]
kaiju_summary_output_file = re.sub(r'\.kaiju.out', '.kaiju_out_species.summary', run_kaiju_output_file)
kaiju_summary_output_file_sing = re.sub(r'\.kaiju.out', '.kaiju_out_species.summary', run_kaiju_output_file_sing)


def kaiju_species_input_file_sub(wildcards):
    """
    Wildcard substitution for (one of the) input files to the kaijuReport
    command. 
    """
    return run_kaiju_output_file_sing.format(**wildcards)

def kaiju_species_output_file_sub(wildcards):
    """
    Wildcard substitution of kaijuReport output.
    """
    return kaiju_summary_output_file_sing.format(**wildcards)


rule kaiju_species_summary_report:
    """
    Generate a kaiju summary report from kaiju results
    """
    input:
        kaiju_summary_input_files
    output:
        kaiju_summary_output_file
    message: 
        '''--- Generating a kaiju report.'''
    singularity:
        kaiju_image
    params:
        kaiju_report_input_wc = kaiju_species_input_file_sub,
        kaiju_report_output_wc = kaiju_species_output_file_sub
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_report_input_wc} '
        '-r species '
        '-o /{params.kaiju_report_output_wc} '




############################################
# Taxonomic Classification:  kaiju species summary from contigs
kaiju_contigs_summary_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_contigs_output_file]
kaiju_contigs_summary_output_file = re.sub(r'\.kaiju.out', '.kaiju_out_species.summary', run_kaiju_contigs_output_file)
kaiju_contigs_summary_output_file_sing = re.sub(r'\.kaiju.out', '.kaiju_out_species.summary', run_kaiju_contigs_output_file_sing)


def kaiju_contigs_species_input_file_sub(wildcards):
    """
    Wildcard substitution for (one of the) input files to the kaijuReport
    command. 
    """
    return run_kaiju_contigs_output_file_sing.format(**wildcards)

def kaiju_contigs_species_output_file_sub(wildcards):
    """
    Wildcard substitution of kaijuReport output.
    """
    return kaiju_contigs_summary_output_file_sing.format(**wildcards)


rule kaiju_contigs_species_summary_report:
    """
    Generate a kaiju summary report from kaiju results with contigs
    """
    input:
        kaiju_contigs_summary_input_files
    output:
        kaiju_contigs_summary_output_file
    message: 
        '''--- Generating a kaiju report from contigs.'''
    singularity:
        kaiju_image
    params:
        kaiju_contigs_report_input_wc = kaiju_contigs_species_input_file_sub,
        kaiju_contigs_report_output_wc = kaiju_contigs_species_output_file_sub
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_contigs_report_input_wc} '
        '-r species '
        '-o /{params.kaiju_contigs_report_output_wc} '



############################################
# Taxonomic Classification: kaiju report

kaiju_report_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_output_file]
kaiju_report_output_file = re.sub(r'\.out','_genus.summary',run_kaiju_output_file)
kaiju_report_output_file_sing = re.sub(r'\.out','_genus.summary',run_kaiju_output_file_sing)
tax_rank = taxclass['kaiju_report']['taxonomic_rank']

def kaiju_report_input_name(wildcards):
    kaiju_report_in = run_kaiju_output_file_sing.format(**wildcards)
    return kaiju_report_in

def kaiju_report_output_name(wildcards):
    kaiju_report_out = kaiju_report_output_file_sing.format(**wildcards)
    return kaiju_report_out

rule kaiju_report:
    """
    Generate a kaiju report from kaiju results
    """
    input:
        kaiju_report_input_files
    output:
        kaiju_report_output_file
    message: 
        '''--- Generating a kaiju report.'''
    singularity:
        kaiju_image
    params:
        kaiju_report_input_wc = kaiju_report_input_name,
        kaiju_report_output_wc = kaiju_report_output_name
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_report_input_wc} '
        '-r {tax_rank} '
        '-o /{params.kaiju_report_output_wc} '



###############################################
# Taxonomic Classification: kaiju report for contigs

kaiju_contigs_report_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_contigs_output_file]

run_kaiju_contigs_output_file = join(data_dir, taxclass['kaiju']['contig_out'])
run_kaiju_output_contigs_file_sing = join(sing_dir, taxclass['kaiju']['contig_out'])


kaiju_contigs_report_output_file = re.sub(r'\.out','_genus.summary',run_kaiju_contigs_output_file)
kaiju_contigs_report_output_file_sing = re.sub(r'\.out','_genus.summary',run_kaiju_output_contigs_file_sing)
contigs_tax_rank = taxclass['contigs_kaiju_report']['contigs_taxonomic_rank']

def kaiju_report_input_name(wildcards):
    kaiju_report_in = run_kaiju_output_contigs_file_sing.format(**wildcards)
    return kaiju_report_in

def kaiju_report_output_name(wildcards):
    kaiju_report_out = kaiju_contigs_report_output_file_sing.format(**wildcards)
    return kaiju_report_out

rule kaiju_contigs_report:
    """
    Generate a kaiju report from kaiju results from contigs
    """
    input:
        kaiju_contigs_report_input_files
    output:
        kaiju_contigs_report_output_file
    message: 
        '''--- Generating a kaiju report from contigs.'''
    singularity:
        kaiju_image
    params:
        kaiju_report_input_wc = kaiju_report_input_name,
        kaiju_report_output_wc = kaiju_report_output_name
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_report_input_wc} '
        '-r {contigs_tax_rank} '
        '-o /{params.kaiju_report_output_wc} '





############################################
# Taxonomic Classification: kaiju filtered report 

filter_taxa_pct = taxclass['kaiju_report']['pct_threshold']

kaiju_filtered_report_suffix = '_genus_filtered{pct}_total.summary'.format(
            pct = filter_taxa_pct)

kaiju_filtered_report_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_output_file]
kaiju_filtered_report_output_file = re.sub(r'\.out',kaiju_filtered_report_suffix,run_kaiju_output_file)
kaiju_filtered_report_output_file_sing = re.sub(r'\.out',kaiju_filtered_report_suffix,run_kaiju_output_file_sing)

def kaiju_filtered_report_input_name(wildcards):
    kaiju_filtered_report_in = run_kaiju_output_file_sing.format(**wildcards)
    return kaiju_filtered_report_in

def kaiju_filtered_report_output_name(wildcards):
    kaiju_filtered_report_out = kaiju_filtered_report_output_file_sing.format(**wildcards)
    return kaiju_filtered_report_out

rule kaiju_filtered_report:
    """
    Generate a kaiju report from *all* kaiju results,
    and filter taxa with a low (less than X percent) abundance.
    """
    input:
        kaiju_filtered_report_input_files
    output:
        kaiju_filtered_report_output_file
    message: 
        '''--- Generating a kaiju report with filtered taxa.'''
    singularity:
        kaiju_image
    params:
        kaiju_filtered_report_input_wc = kaiju_filtered_report_input_name,
        kaiju_filtered_report_output_wc = kaiju_filtered_report_output_name
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_filtered_report_input_wc} '
        '-r {tax_rank} '
        '-m {filter_taxa_pct} '
        '-o /{params.kaiju_filtered_report_output_wc} '



############################################
# Taxonomic Classification: kaiju filtered contigs report 

filter_contigs_taxa_pct = taxclass['contigs_kaiju_report']['contigs_pct_threshold']

kaiju_filtered_contigs_report_suffix = '_genus_filtered{pct}_total.summary'.format(
            pct = filter_taxa_pct)

kaiju_filtered_report_contigs_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_contigs_output_file]
kaiju_filtered_report_contigs_output_file = re.sub(r'\.out',kaiju_filtered_contigs_report_suffix, run_kaiju_contigs_output_file)
kaiju_filtered_report_contigs_output_file_sing = re.sub(r'\.out',kaiju_filtered_contigs_report_suffix, run_kaiju_contigs_output_file_sing)

def kaiju_filtered_report_contigs_input_name(wildcards):
    kaiju_filtered_report_in = run_kaiju_contigs_output_file_sing.format(**wildcards)
    return kaiju_filtered_report_in

def kaiju_filtered_report_contigs_output_name(wildcards):
    kaiju_filtered_report_out = kaiju_filtered_report_contigs_output_file_sing.format(**wildcards)
    return kaiju_filtered_report_out

rule kaiju_filtered_contigs_report:
    """
    Generate a kaiju report with contigs from *all* kaiju results,
    and filter taxa with a low (less than X percent) abundance from contigs.
    """
    input:
        kaiju_filtered_report_contigs_input_files
    output:
        kaiju_filtered_report_contigs_output_file
    message: 
        '''--- Generating a kaiju report with filtered taxa from contigs.'''
    singularity:
        kaiju_image
    params:
        kaiju_filtered_report_input_wc = kaiju_filtered_report_contigs_input_name,
        kaiju_filtered_report_output_wc = kaiju_filtered_report_contigs_output_name
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_filtered_report_input_wc} '
        '-r {contigs_tax_rank} '
        '-m {filter_contigs_taxa_pct} '
        '-o /{params.kaiju_filtered_report_output_wc} '


############################################
# Taxonomic Classification: kaiju filtered and classified report 

kaiju_filteredclass_report_suffix = '_genus_filtered{pct}_classified.summary'.format(
            pct = filter_taxa_pct)

kaiju_filteredclass_report_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_output_file]
kaiju_filteredclass_report_output_file = re.sub(r'\.out',kaiju_filteredclass_report_suffix,run_kaiju_output_file)
kaiju_filteredclass_report_output_file_sing = re.sub(r'\.out',kaiju_filteredclass_report_suffix,run_kaiju_output_file_sing)

def kaiju_filteredclass_report_input_name(wildcards):
    kaiju_filteredclass_report_in = run_kaiju_output_file_sing.format(**wildcards)
    return kaiju_filteredclass_report_in

def kaiju_filteredclass_report_output_name(wildcards):
    kaiju_filteredclass_report_out = kaiju_filteredclass_report_output_file_sing.format(**wildcards)
    return kaiju_filteredclass_report_out


rule kaiju_filteredclass_report:
    """
    Generate a kaiju report from *classified* kaiju results,
    and filter taxa with a low (<X%) abundance.
    """
    input:
        kaiju_filteredclass_report_input_files
    output:
        kaiju_filteredclass_report_output_file
    message: 
        '''--- Generating a kaiju report with filtered, classified taxa.'''
    singularity:
        kaiju_image
    params:
        kaiju_filteredclass_report_input_wc = kaiju_filteredclass_report_input_name,
        kaiju_filteredclass_report_output_wc = kaiju_filteredclass_report_output_name
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_filteredclass_report_input_wc} '
        '-r {tax_rank} '
        '-m {filter_taxa_pct} '
        '-u '
        '-o /{params.kaiju_filteredclass_report_output_wc} '



###########################################
# Taxonomic Classification: kaiju filtered and classified report from contigs 

kaiju_filteredclass_contigs_report_suffix = '_genus_filtered{pct}_classified.summary'.format(
            pct = filter_contigs_taxa_pct)

kaiju_filteredclass_report_contigs_input_files = [kaiju_dmp1, kaiju_dmp2, run_kaiju_contigs_output_file]
kaiju_filteredclass_report_contigs_output_file = re.sub(r'\.out',kaiju_filteredclass_contigs_report_suffix, run_kaiju_contigs_output_file)
kaiju_filteredclass_report_contigs_output_file_sing = re.sub(r'\.out',kaiju_filteredclass_contigs_report_suffix, run_kaiju_contigs_output_file_sing)

def kaiju_filteredclass_report_contigs_input_name(wildcards):
    kaiju_filteredclass_report_in = run_kaiju_contigs_output_file_sing.format(**wildcards)
    return kaiju_filteredclass_report_in

def kaiju_filteredclass_report_contigs_output_name(wildcards):
    kaiju_filteredclass_report_out = kaiju_filteredclass_report_contigs_output_file_sing.format(**wildcards)
    return kaiju_filteredclass_report_out

rule kaiju_filteredclass_contigs_report:
    """
    Generate a kaiju report from *classified* kaiju results,
    and filter taxa with a low (<X%) abundance from contigs.
    """
    input:
        kaiju_filteredclass_report_contigs_input_files
    output:
        kaiju_filteredclass_report_contigs_output_file
    message: 
        '''--- Generating a kaiju report with filtered, classified taxa from contigs.'''
    singularity:
        kaiju_image
    params:
        kaiju_filteredclass_report_contigs_input_wc = kaiju_filteredclass_report_contigs_input_name,
        kaiju_filteredclass_report_contigs_output_wc = kaiju_filteredclass_report_contigs_output_name
    shell:
        'kaijuReport '
        '-v '
        '-t /{kaiju_dmp1_sing} '
        '-n /{kaiju_dmp2_sing} '
        '-i /{params.kaiju_filteredclass_report_contigs_input_wc} '
        '-r {contigs_tax_rank} '
        '-m {filter_contigs_taxa_pct} '
        '-u '
        '-o /{params.kaiju_filteredclass_report_contigs_output_wc} '

############################################
# Taxonomic Classification: generate krona HTML using all results


visualize_krona_input_file = kaiju_report_output_file
visualize_krona_output_file = re.sub( r'.genus.summary', '_genus_krona.html', visualize_krona_input_file)
visualize_krona_input_file_sing = kaiju_report_output_file_sing
visualize_krona_output_file_sing = re.sub( r'.genus.summary', '_genus_krona.html', visualize_krona_input_file_sing)

krona_image = container_image_name(biocontainers, 'krona')


def visualize_krona_input_func_sing(wildcards):
    return visualize_krona_input_file_sing.format(**wildcards)

def visualize_krona_output_func_sing(wildcards):
    return visualize_krona_output_file_sing.format(**wildcards)

rule visualize_krona:
    """
    Visualize all kaiju results using krona
    """
    input:
       visualize_krona_input_file
    output:
        visualize_krona_output_file
    message:
        '''--- Creating krona report from all kaiju results.'''
    params:
        visualize_krona_input_wc = visualize_krona_input_func_sing,
        visualize_krona_output_wc = visualize_krona_output_func_sing,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_krona_output_wc} '
        '/{params.visualize_krona_input_wc} '


############################################
# Taxonomic Classification: generate krona HTML using all results with contigs


visualize_krona_contigs_input_file = kaiju_contigs_report_output_file
visualize_krona_contigs_output_file = re.sub( r'.genus.summary', '_genus_krona.html', visualize_krona_contigs_input_file)
visualize_krona_contigs_input_file_sing = kaiju_contigs_report_output_file_sing
visualize_krona_contigs_output_file_sing = re.sub( r'.genus.summary', '_genus_krona.html', visualize_krona_contigs_input_file_sing)

krona_image = container_image_name(biocontainers, 'krona')


def visualize_krona_contigs_input_func_sing(wildcards):
    return visualize_krona_contigs_input_file_sing.format(**wildcards)

def visualize_krona_contigs_output_func_sing(wildcards):
    return visualize_krona_contigs_output_file_sing.format(**wildcards)

rule visualize_contigs_krona:
    """
    Visualize all kaiju results using krona with contigs
    """
    input:
       visualize_krona_contigs_input_file
    output:
        visualize_krona_contigs_output_file
    message:
        '''--- Creating krona report from all contigs kaiju results.'''
    params:
        visualize_krona_contigs_input_wc = visualize_krona_contigs_input_func_sing,
        visualize_krona_contigs_output_wc = visualize_krona_contigs_output_func_sing,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_krona_contigs_output_wc} '
        '/{params.visualize_krona_contigs_input_wc} '



############################################
# Taxonomic Classification: generate krona HTML using all >1% filter

visualize_krona_filtered_input_file = kaiju_filtered_report_output_file
visualize_krona_filtered_output_file = re.sub(
    r'.genus_filtered1_total.summary', '_genus_krona_filtered1_total.html', visualize_krona_filtered_input_file
)
visualize_krona_filtered_input_file_sing = kaiju_filtered_report_output_file_sing
visualize_krona_filtered_output_file_sing = re.sub(
    r'.genus_filtered1_total.summary', '_genus_krona_filtered1_total.html', visualize_krona_filtered_input_file_sing
)


def visualize_krona_filtered_input_func(wildcards):
    return visualize_krona_filtered_input_file_sing.format(**wildcards)

def visualize_krona_filtered_output_func(wildcards):
    return visualize_krona_filtered_output_file_sing.format(**wildcards)

rule visualize_krona_filtered:
    """
    Visualize filtered (>X%) kaiju results using krona 
    """
    input:
        visualize_krona_filtered_input_file
    output:
        visualize_krona_filtered_output_file
    message:
        '''--- Creating krona report from filtered kaiju results.'''
    params:
        visualize_krona_filtered_input_wc  = visualize_krona_filtered_input_func,
        visualize_krona_filtered_output_wc = visualize_krona_filtered_output_func,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_krona_filtered_output_wc} '
        '/{params.visualize_krona_filtered_input_wc} '



############################################
# Taxonomic Classification: generate krona HTML using all >1% filter from contigs
#TODO: The pct is hard coded in here
visualize_krona_filtered_contigs_input_file = kaiju_filtered_report_contigs_output_file
visualize_krona_filtered_contigs_output_file = re.sub(
    r'.genus_filtered1_total.summary', '_genus_krona_filtered1_total.html', visualize_krona_filtered_contigs_input_file
)
visualize_krona_filtered_contigs_input_file_sing = kaiju_filtered_report_contigs_output_file_sing
visualize_krona_filtered_output_contigs_file_sing = re.sub(
    r'.genus_filtered1_total.summary', '_genus_krona_filtered1_total.html', visualize_krona_filtered_contigs_input_file_sing
)


def visualize_krona_filtered_contigs_input_func(wildcards):
    return visualize_krona_filtered_contigs_input_file_sing.format(**wildcards)

def visualize_krona_filtered_contigs_output_func(wildcards):
    return visualize_krona_filtered_output_contigs_file_sing.format(**wildcards)


rule visualize_krona_contigs_filtered:
    """
    Visualize filtered (>X%) kaiju results using krona with contigs
    """
    input:
        visualize_krona_filtered_contigs_input_file
    output:
        visualize_krona_filtered_contigs_output_file
    message:
        '''--- Creating krona report from filtered kaiju results with contigs.'''
    params:
        visualize_krona_filtered_input_wc  = visualize_krona_filtered_contigs_input_func,
        visualize_krona_filtered_output_wc = visualize_krona_filtered_contigs_output_func,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_krona_filtered_output_wc} '
        '/{params.visualize_krona_filtered_input_wc} '


############################################
# Taxonomic Classification: generate krona HTML using classified >1% filter

visualize_krona_filteredclass_input_file = kaiju_filteredclass_report_output_file
visualize_krona_filteredclass_output_file = re.sub(
    r'.genus_filtered1_classified.summary', '_genus_krona_filtered1_classified.html', visualize_krona_filteredclass_input_file
)

visualize_krona_filteredclass_input_file_sing = kaiju_filteredclass_report_output_file_sing
visualize_krona_filteredclass_output_file_sing = re.sub(
    r'.genus_filtered1_classified.summary', '_genus_krona_filtered1_classified.html', visualize_krona_filteredclass_input_file_sing
)

def visualize_krona_filteredclass_input_func(wildcards):
    return visualize_krona_filtered_input_file_sing.format(**wildcards)

def visualize_krona_filteredclass_output_func(wildcards):
    return visualize_krona_filteredclass_output_file_sing.format(**wildcards)

rule visualize_krona_filteredclass:
    """
    Visualize classified, filtered (>X%) kaiju results using krona
    """
    input:
        visualize_krona_filteredclass_input_file
    output:
        visualize_krona_filteredclass_output_file
    message:
        '''--- Creating krona report from classified, filtered kaiju results.'''
    params:
        visualize_krona_filteredclass_input_wc  = visualize_krona_filteredclass_input_func,
        visualize_krona_filteredclass_output_wc = visualize_krona_filteredclass_output_func,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_krona_filteredclass_output_wc} '
        '/{params.visualize_krona_filteredclass_input_wc} '


############################################
# Taxonomic Classification: generate krona HTML using classified >1% filter from contigs

visualize_krona_filteredclass_contigs_input_file = kaiju_filteredclass_report_contigs_output_file
visualize_krona_filteredclass_contigs_output_file = re.sub(
    r'.genus_filtered1_classified.summary', '_genus_krona_filtered1_classified.html', visualize_krona_filteredclass_contigs_input_file
)

visualize_krona_filteredclass_contigs_input_file_sing = kaiju_filteredclass_report_contigs_output_file_sing
visualize_krona_filteredclass_contigs_output_file_sing = re.sub(
    r'.genus_filtered1_classified.summary', '_genus_krona_filtered1_classified.html', visualize_krona_filteredclass_contigs_input_file_sing
)

def visualize_krona_filteredclass_contigs_input_func(wildcards):
    return visualize_krona_filteredclass_contigs_input_file_sing.format(**wildcards)

def visualize_krona_filteredclass_contigs_output_func(wildcards):
    return visualize_krona_filteredclass_contigs_output_file_sing.format(**wildcards)

rule visualize_krona_contigs_filteredclass:
    """
    Visualize classified, filtered (>X%) kaiju results using krona with contigs
    """
    input:
        visualize_krona_filteredclass_contigs_input_file
    output:
        visualize_krona_filteredclass_contigs_output_file
    message:
        '''--- Creating krona report from classified, filtered kaiju results with contigs.'''
    params:
        visualize_krona_filteredclass_input_wc  = visualize_krona_filteredclass_contigs_input_func,
        visualize_krona_filteredclass_output_wc = visualize_krona_filteredclass_contigs_output_func,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_krona_filteredclass_output_wc} '
        '/{params.visualize_krona_filteredclass_input_wc} '



############################################
# Taxonomic Classification: generate krona HTML using species summary results

visualize_kaiju_species_input_file = kaiju_summary_output_file
visualize_kaiju_species_input_file_sing = kaiju_summary_output_file_sing
visualize_kaiju_species_output_file = re.sub( r'.kaiju_out_species.summary', '.kaiju_species_krona.html', visualize_kaiju_species_input_file)
visualize_kaiju_species_output_file_sing = re.sub( r'.kaiju_out_species.summary', '.kaiju_species_krona.html', visualize_kaiju_species_input_file_sing)

krona_image = container_image_name(biocontainers, 'krona')


def visualize_kaiju_species_input_func_sing(wildcards):
    return visualize_kaiju_species_input_file_sing.format(**wildcards)

def visualize_kaiju_species_output_func_sing(wildcards):
    return visualize_kaiju_species_output_file_sing.format(**wildcards)

rule visualize_kaiju_species:
    """
    Visualize all kaiju species using krona
    """
    input:
        visualize_kaiju_species_input_file
    output:
        visualize_kaiju_species_output_file
    message:
        '''--- Creating krona report from species summary report.'''
    params:
        visualize_kaiju_species_input_wc = visualize_kaiju_species_input_func_sing,
        visualize_kaiju_species_output_wc = visualize_kaiju_species_output_func_sing,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_kaiju_species_output_wc} '
        '/{params.visualize_kaiju_species_input_wc} '


############################################
# Taxonomic Classification: generate krona HTML using species summary results from contigs

visualize_kaiju_species_contigs_input_file = kaiju_contigs_summary_output_file
visualize_kaiju_species_contigs_input_file_sing = kaiju_contigs_summary_output_file_sing
visualize_kaiju_species_contigs_output_file = re.sub( r'.kaiju_out_species.summary', '.kaiju_species_krona.html', visualize_kaiju_species_contigs_input_file)
visualize_kaiju_species_contigs_output_file_sing = re.sub( r'.kaiju_out_species.summary', '.kaiju_species_krona.html', visualize_kaiju_species_contigs_input_file_sing)

krona_image = container_image_name(biocontainers, 'krona')


def visualize_kaiju_species_contigs_input_func_sing(wildcards):
    return visualize_kaiju_species_contigs_input_file_sing.format(**wildcards)

def visualize_kaiju_species_contigs_output_func_sing(wildcards):
    return visualize_kaiju_species_contigs_output_file_sing.format(**wildcards)


rule visualize_kaiju_species_contigs:
    """
    Visualize all kaiju species using krona from contigs
    """
    input:
        visualize_kaiju_species_contigs_input_file
    output:
        visualize_kaiju_species_contigs_output_file
    message:
        '''--- Creating krona report from species summary report from contigs.'''
    params:
        visualize_kaiju_species_input_wc = visualize_kaiju_species_contigs_input_func_sing,
        visualize_kaiju_species_output_wc = visualize_kaiju_species_contigs_output_func_sing,
    singularity:
        krona_image
    shell:
        'ktImportText '
        '-o /{params.visualize_kaiju_species_output_wc} '
        '/{params.visualize_kaiju_species_input_wc} '





############################################
# Taxonomic Classification: kraken2


kraken2_input_pattern = join(data_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']))
kraken2_input_pattern_sing = join(sing_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']))

kraken2_input_fwd = kraken2_input_pattern.format(
            direction=readfilt['direction_labels']['forward'], 
            sample='{sample}', 
            qual='{qual}',
            db ='{db}',
            conf='{conf}'
)

kraken2_input_rev = kraken2_input_pattern.format(
            direction=readfilt['direction_labels']['reverse'], 
            sample='{sample}', 
            qual='{qual}',
            db ='{db}',
            conf='{conf}'
)

kraken2_input_fwd_sing = kraken2_input_pattern_sing.format(
            direction=readfilt['direction_labels']['forward'], 
            sample='{sample}', 
            qual='{qual}',
            db ='{db}',
            conf='{conf}'
)
kraken2_input_rev_sing = kraken2_input_pattern_sing.format(
            direction=readfilt['direction_labels']['reverse'], 
            sample='{sample}', 
            qual='{qual}',
            db ='{db}',
            conf='{conf}'
)

kraken2_ouput = join(data_dir, taxclass['kraken2']['kraken2_output'] )
kraken2_ouput_sing = join(sing_dir, taxclass['kraken2']['kraken2_output'] )

kraken2_image = container_image_name(biocontainers, 'kraken2')
kraken2_threads = taxclass['kraken2']['threads'] 
kraken2_unclass_out = join(sing_dir, taxclass['kraken2']['unclass_out'])
kraken2_class_out = join(sing_dir, taxclass['kraken2']['class_out'])
kraken2_report_sing = join(sing_dir, taxclass['kraken2']['report'])
kraken2_report = join(data_dir, taxclass['kraken2']['report'])
kraken2_db_sing = join(sing_dir, '{db}')


rule kraken2:
    """
    we do something with kraken2 here
    """
    input:
        fwd = kraken2_input_fwd,
        rev = kraken2_input_rev,
    output:
        kraken2_ouput
    message:
        '''--- Running kraken2.'''
    threads:
        kraken2_threads
    singularity:
        kraken2_image
    params:
        fwd_sing = kraken2_input_fwd_sing,
        rev_sing = kraken2_input_rev_sing,
        db_sing = kraken2_db_sing,
        unclass_out = kraken2_unclass_out,
        class_out = kraken2_class_out,
        out_sing = kraken2_ouput_sing,
        report = kraken2_report_sing
    shell:
        'kraken2 '
        '--db {params.db_sing} '
        '--threads {threads} '
        '--paired {params.fwd_sing} {params.rev_sing} '
        '--use-names '
        '--confidence {wildcards.conf} '
        '--report {params.report} '
        '--unclassified-out {params.unclass_out} '
        '--classified-out {params.class_out} '
        '--output {params.out_sing}'



############################################
# Taxonomic Classification: bracken

bracken_input_raw = kraken2_report
bracken_input_raw_sing = kraken2_report_sing

bracken_input = bracken_input_raw.replace('.report','')
bracken_input_sing = bracken_input_raw_sing.replace('.report','')

bracken_output_pattern = taxclass['bracken']['bracken_output']
bracken_output_raw = bracken_output_pattern.format(
             read_length = '{read_length}',
             level = '{level}',
             threshold = '{threshold}',
             bdb = '{bdb}'
)

bracken_output = bracken_input + bracken_output_raw
bracken_output_sing = bracken_input_sing + bracken_output_raw

bracken_image = container_image_name(biocontainers, 'bracken')


def get_braken_DB(wildcards):
    return join(sing_dir, wildcards.bdb)

rule bracken:
    """
    we do something with bracken here
    """
    input:
        bracken_input = bracken_input_raw
    output:
        bracken_output
    message:
        '''--- Running bracken.'''
    singularity:
        bracken_image
    params:
        bracken_input_sing = bracken_input_raw_sing,
        bracken_output = bracken_output_sing,
        db_sing = get_braken_DB,
        read_length = '{read_length}',
        level = '{level}',
        threshold = '{threshold}',
    shell:
        'bracken '
        ' -d {params.db_sing} '
        ' -i {params.bracken_input_sing} '
        ' -r {params.read_length} '
        ' -l {params.level} '
        ' -t {params.threshold} '
        ' -o {params.bracken_output} '

############################################
# Taxonomic Classification: krakenUniq


krakenuniq_input_pattern = join(data_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']))
krakenuniq_input_pattern_sing = join(sing_dir, (readfilt['read_patterns']['post_trimming_pattern']+readfilt['quality_trimming']['sample_file_ext']))

krakenuniq_input_fwd = krakenuniq_input_pattern.format(
            direction=readfilt['direction_labels']['forward'], 
            sample='{sample}', 
            qual='{qual}',
            db = '{db}',
            hll_prec = '{hll}'
)
krakenuniq_input_rev = krakenuniq_input_pattern.format(
            direction=readfilt['direction_labels']['reverse'], 
            sample='{sample}', 
            qual='{qual}',
            db = '{db}',
            hll_prec = '{hll}'
)

krakenuniq_input_fwd_sing = krakenuniq_input_pattern_sing.format(
            direction=readfilt['direction_labels']['forward'], 
            sample='{sample}', 
            qual='{qual}',
            db = '{db}',
            hll_prec = '{hll}'
)
krakenuniq_input_rev_sing = krakenuniq_input_pattern_sing.format(
            direction=readfilt['direction_labels']['reverse'], 
            sample='{sample}', 
            qual='{qual}',
            db = '{db}',
            hll_prec = '{hll}'
)

krakenuniq_ouput = join(data_dir, taxclass['krakenuniq']['krakenuniq_output'] )
krakenuniq_ouput_sing = join(sing_dir, taxclass['krakenuniq']['krakenuniq_output'] )


krakenuniq_image = container_image_name(biocontainers, 'krakenuniq')
krakenuniq_threads = taxclass['krakenuniq']['threads'] 
krakenuniq_unclass_out = join(sing_dir, taxclass['krakenuniq']['unclass_out'])
krakenuniq_class_out = join(sing_dir, taxclass['krakenuniq']['class_out'])
krakenuniq_report = join(sing_dir, taxclass['krakenuniq']['report'])
krakenuniq_db_sing = join(sing_dir, '{db}')




rule krakenuniq:
    """
    we do something with krakenuniq here
    """
    input:
        fwd = krakenuniq_input_fwd,
        rev = krakenuniq_input_rev,
    output:
        krakenuniq_ouput
    message:
        '''--- Running krakenuniq.'''
    threads:
        krakenuniq_threads
    singularity:
        krakenuniq_image
    params:
        fwd_sing = krakenuniq_input_fwd_sing,
        rev_sing = krakenuniq_input_rev_sing,
        db_sing = krakenuniq_db_sing,
        unclass_out = krakenuniq_unclass_out,
        class_out = krakenuniq_class_out,
        out_sing = krakenuniq_ouput_sing,
        report = krakenuniq_report,
    shell:
        'krakenuniq '
        '--paired {params.fwd_sing} {params.rev_sing} '
        '--db {params.db_sing} '
        '--threads {threads} '
        '--hll-precision {wildcards.hll_prec} '
        '--report-file {params.report} '
        '--unclassified-out {params.unclass_out} '
        '--classified-out {params.class_out} '
        '--output {params.out_sing}'
        

        


############################################
# Taxonomic Classification:  mash dist with reference DB

mash_dist_input = interleave_output
mash_dist_input_sing = mash_dist_input.replace(data_dir, sing_dir)

mash_dist_output = join(data_dir, taxclass['mash']['mash_dist_out'] )
mash_dist_output = mash_dist_output.format(
    db = '{db}', sample='{sample}', qual='{qual}')
mash_dist_output_sing = join(sing_dir, taxclass['mash']['mash_dist_out'] )
mash_db = join(sing_dir, '{db}' )
mash_image = container_image_name(biocontainers, 'mash')


rule mash_dist_db:
    input:
        mash_dist_input
    output:
        mash_dist_output
    message:
        '''--- Running mash dist.'''
    singularity:
        mash_image
    params:
        mash_input = mash_dist_input_sing,
        mash_output = mash_dist_output_sing,
        mash_db_sing = mash_db
    shell:
        'mash dist '  
        '{params.mash_db_sing} '
        '{params.mash_input} '
        '> {params.mash_output} '



############################################
# Taxonomic Classification:  mash screen results

mash_sort_input = mash_dist_output
mash_sort_ouput_pattern = join(data_dir, taxclass['mash']['mash_dist_sort_out'] )
mash_dist_sort_output = mash_sort_ouput_pattern.format(
   sample='{sample}', qual='{qual}', db = '{db}',)



rule mash_sort:
    input:
        mash_sort_input
    output:
        mash_dist_sort_output
    shell:
        "sort -gk3 "
        "{input} > {output} "




############################################
# Taxonomic Classification:  mash screen 

mash_screen_input = interleave_output
mash_screen_input_sing = interleave_output.replace(data_dir, sing_dir)

mash_screen_output = join(data_dir, taxclass['mash']['mash_screen_out'] )
mash_screen_output = mash_screen_output.format(
    db = '{db}', sample='{sample}', qual='{qual}')
mash_screen_output_sing = join(sing_dir, taxclass['mash']['mash_screen_out'] )


rule mash_screen_db:
    input:
        mash_screen_input
    output:
        mash_screen_output
    message:
        '''--- Running mash screen.'''
    singularity:
        mash_image
    params:
        mash_input = mash_screen_input_sing,
        mash_output = mash_screen_output_sing,
        mash_db_sing = mash_db
    shell:
        'mash screen '  
        '{params.mash_db_sing} '
        '{params.mash_input} '
        '> {params.mash_output} '


############################################
# Taxonomic Classification:  mash screen results

mash_screen_sort_input = mash_screen_output
mash_screen_sort_ouput_pattern = join(data_dir, taxclass['mash']['mash_screen_sort_out'] )
mash_screen_sort_output = mash_screen_sort_ouput_pattern.format(
   sample='{sample}', qual='{qual}', db = '{db}')



rule mash_screen_sort:
    input:
        mash_screen_sort_input
    output:
        mash_screen_sort_output
    shell:
        "sort -gr "
        "{input} > {output} "


############################################
# Taxonomic Classification:  update MTSV databases

mtsv_threads = taxclass['mtsv']['threads']
mtsv_customdb_name = '"' + taxclass['mtsv']['customdb_name'] + '"'
mtsv_partitions = taxclass['mtsv']['partitions']
mtsv_image = container_image_name(biocontainers, 'mtsv')
mtsv_sing_db = join(sing_dir, taxclass['mtsv']['db_name'])
mtsv_sing_db = '"' + mtsv_sing_db + '"'
mtsv_db = join(data_dir, taxclass['mtsv']['db_name'])
print(mtsv_sing_db)
print(type(mtsv_sing_db))

rule tax_class_mtsv_update_db:
    output:
        directory(mtsv_db)
    singularity:
        mtsv_image
    params:
        sing_db = mtsv_sing_db,
        threads = mtsv_threads,
        customdb_name = mtsv_customdb_name,
        partitions = mtsv_partitions
    shell:
        "mtsv_setup json_update "
        "--path {params.sing_db} && "
        "mtsv_setup custom_db "
        "--path {params.sing_db} -t {params.threads} "
        "--customdb {params.customdb_name} --partitions {params.partitions}"

############################################
# Taxonomic Classification:  create MTSV File

mtsv_cfg_dest = join(data_dir,  'mtsv.cfg')
mtsv_cfg_src = join('..','resources', 'mtsv.cfg')

input_files = taxclass['mtsv']['input_files']
mtsv_sing_dir_path = join(sing_dir,taxclass['mtsv']['sample_name']+'_MTSV')
mtsv_kmer_output = taxclass['mtsv']['kmer']
mtsv_db_config = sing_dir + "/" + taxclass['mtsv']['db_name'] + "/artifacts/complete_genome.json"
mtsv_n_kmers = taxclass['mtsv']['n_kmers']
mtsv_signature_cutoff = taxclass['mtsv']['signature_cutoff']


rule mtsv_update_cfg:
    output:
        mtsv_cfg_dest
    params:
        src = mtsv_cfg_src,
        dest = mtsv_cfg_dest,
        data_dir = mtsv_sing_dir_path,
        input_files = input_files,
        kmer_output = mtsv_kmer_output,
        database_config_output = mtsv_db_config,
        n_kmers_output = mtsv_n_kmers,
        signature_cutoff_output = mtsv_signature_cutoff
    run:
        with open(params.src, 'r') as f:
            s1 = f.read().replace("{fastq_output}", params.input_files, 1)
            s2 = s1.replace("{data_dir}", params.data_dir, 15)
            s3 = s2.replace("{kmer_output}", str(params.kmer_output), 1)
            s4 = s3.replace("{database_config}", params.database_config_output)
            s5 = s4.replace("{n_kmers}",str(params.n_kmers_output),1)
            s6 = s5.replace("{signature_cutoff}", str(params.signature_cutoff_output),1)
        with open(params.dest, 'w') as f:
            f.write(s6)



############################################
# Taxonomic Classification:  run MTSV 


output_summary_file = join(data_dir,taxclass['mtsv']['sample_name']+'_MTSV','Summary','summary.csv')
mtsv_cfg_sing_dest = join(sing_dir, 'mtsv.cfg')

rule tax_class_run_mtsv:
    input:
        mtsv_cfg_dest
    output:
        output_summary_file
    singularity:
        mtsv_image
    params:
        cfg = mtsv_cfg_sing_dest,
        threads = mtsv_threads
    shell:
        "mtsv readprep -c {params.cfg} && "
        "mtsv binning -c {params.cfg} --cores -t {params.threads} && "
        "mtsv summary -c {params.cfg} --cores -t {params.threads} && "
        "mtsv summary -c {params.cfg} --cores -t {params.threads} && "
        "mtsv analyze -c {params.cfg} --cores -t {params.threads}"






###################################
# Taxonomic Classification: build rules

workflows = config['workflows']

directions = [readfilt['direction_labels']['forward'],
              readfilt['direction_labels']['reverse']]

rule tax_class_signatures_workflow:
    """
    Build rule: trigger calculation of signatures from reads.
    Note:This runs the comparison/compute_read_signatures_rule
    """
    input:
        expand(compute_read_sig_output,
                sample    = sample_input_files,
                qual    = workflows['tax_class_signatures_workflow']['qual'], 
        )


rule tax_class_gather_workflow:
    """
    Gather and compare read signatures using sourmash gather
    """
    input:
        expand( compute_read_sig_output,
                sample    = sample_input_files,
                qual = workflows['tax_class_gather_workflow']['qual']
        ),
        expand( gather_csv,
                sample    = sample_input_files,
                kvalue = workflows['tax_class_gather_workflow']['kvalues'],
                qual = workflows['tax_class_gather_workflow']['qual']
        )


rule tax_class_kaijureport_workflow:
    """
    Run kaiju and generate a report from all (except contigs)results.
    """
    input:
        expand( kaiju_report_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_kaijureport_workflow']['qual']
        )


rule tax_class_kaijureport_contigs_workflow:
    """
    Run kaiju and generate a report from all contigs results.
    """
    input:
        expand( kaiju_contigs_report_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_kaijureport_contigs_workflow']['qual'],
                assembler = workflows['tax_class_kaijureport_contigs_workflow']['assembler']
        )


rule tax_class_kaijureport_filtered_workflow:
    """
    Run kaiju and generate a report from filtered
    results (taxa with <X% abundance).
    """
    input:
        expand( kaiju_filtered_report_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_kaijureport_filtered_workflow']['qual']
        )


rule tax_class_kaijureport_filtered_contigs_workflow:
    """
    Run kaiju and generate a report from contigs filtered
    results (taxa with <X% abundance).
    """
    input:
        expand( kaiju_filtered_report_contigs_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_kaijureport_filtered_contigs_workflow']['qual'],
                assembler = workflows['tax_class_kaijureport_filtered_contigs_workflow']['assembler']
        )


rule tax_class_kaijureport_filteredclass_workflow:
    """
    Run kaiju and generate a report from filtered, classified
    results (taxa with <X% abundance).
    """
    input:
        expand( kaiju_filteredclass_report_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_kaijureport_filteredclass_workflow']['qual']
        )


rule tax_class_kaijureport_filteredclass_contigs_workflow:
    """
    Run kaiju and generate a report from contigs filtered, classified
    results (taxa with <X% abundance).
    """
    input:
        expand( kaiju_filteredclass_report_contigs_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_kaijureport_filteredclass_contigs_workflow']['qual'],
                assembler = workflows['tax_class_kaijureport_filteredclass_contigs_workflow']['assembler']
        )


rule tax_class_add_taxonnames_workflow:
    """
    Takes the output tsv from kaiju run (*.out) and adss the associated taxon names for each result (*.names.out)
    Runs def run_kaiju -> def add_taxon_names
    """
    input:
        expand( taxon_names_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_add_taxonnames_workflow']['qual']
        )


rule tax_class_add_taxonnames_to_contigs_workflow:
    """
    Takes the output tsv from contigs kaiju run (*.out) and adds the associated taxon names for each result (*.names.out)
    Runs def run_kaiju -> def add_taxon_names
    """
    input:
        expand( taxon_names_contigs_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_add_taxonnames_workflow']['qual'],
                assembler = workflows['tax_class_add_taxonnames_contigs_workflow']['assembler']
        )


rule tax_class_convert_kaiju_to_krona_workflow:
    """
    converts kaiju output to krona input format (*.kaiju_out_krona)
    Create a krona file out of the kaiju results
    Runs def run_kaiju -> def kaiju2krona
    """
    input:
        expand( kaiju2krona_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_convert_kaiju_to_krona_workflow']['qual']
        )


rule tax_class_kaiju_species_summary_workflow:
    """
    Labels the krona results down to the species level (default is the genus level
    Create a kaiju species summary results file
    Runs def run_kaiju -> def kaiju_species_summary_report
    """
    input:
        expand( kaiju_summary_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_kaiju_species_summary_workflow']['qual']
        )


rule tax_class_kaiju_species_summary_contigs_workflow:
    """
    Labels the contigs krona results down to the species level (default is the genus level
    Create a kaiju species summary results file from contigs
    Runs def run_kaiju -> def kaiju_species_summary_report
    """
    input:
        expand( kaiju_contigs_summary_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_kaiju_species_summary_contigs_workflow']['qual'],
                assembler = workflows['tax_class_kaiju_species_summary_contigs_workflow']['assembler']
        )


rule tax_class_visualize_krona_kaijureport_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from kaiju report
    '''
    input:
        expand( visualize_krona_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_visualize_krona_kaijureport_workflow']['qual']
        )


rule tax_class_visualize_krona_kaijureport_contigs_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from kaiju report from contigs
    '''
    input:
        expand( visualize_krona_contigs_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_visualize_krona_kaijureport_contigs_workflow']['qual'],
                assembler = workflows['tax_class_visualize_krona_kaijureport_contigs_workflow']['assembler']
        )


rule tax_class_visualize_krona_kaijureport_filtered_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from kaiju filtered report
    '''
    input:
        expand( visualize_krona_filtered_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_visualize_krona_kaijureport_filtered_workflow']['qual']
        )


rule tax_class_visualize_krona_kaijureport_filtered_contigs_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from kaiju filtered report from contigs
    '''
    input:
        expand( visualize_krona_filtered_contigs_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_visualize_krona_kaijureport_filtered_contigs_workflow']['qual'],
                assembler = workflows['tax_class_visualize_krona_kaijureport_filtered_contigs_workflow']['assembler']
        )


rule tax_class_visualize_krona_kaijureport_filteredclass_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from kaiju filtered, classified report
    '''
    input:
        expand( visualize_krona_filteredclass_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_visualize_krona_kaijureport_filteredclass_workflow']['qual']
        )


rule tax_class_visualize_krona_kaijureport_filteredclass_contigs_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from kaiju filtered, classified report from contigs
    '''
    input:
        expand( visualize_krona_filteredclass_contigs_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_visualize_krona_kaijureport_filteredclass_contigs_workflow']['qual'],
                assembler = workflows['tax_class_visualize_krona_kaijureport_filteredclass_contigs_workflow']['assembler']
        )


rule tax_class_visualize_krona_species_summary_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from species summary report
    '''
    input:
        expand( visualize_kaiju_species_output_file,
                sample    = sample_input_files,
                qual   = workflows['tax_class_visualize_krona_species_summary_workflow']['qual']
        )


rule tax_class_visualize_krona_species_summary_contigs_workflow:
    '''
    Generates interactive krona plot (*.html) of the results from species summary report from contigs
    '''
    input:
        expand( visualize_kaiju_species_contigs_output_file,
                sample    = sample_input_files,
                qual      = workflows['tax_class_visualize_krona_species_summary_contigs_workflow']['qual'],
                assembler = workflows['tax_class_visualize_krona_species_summary_contigs_workflow']['assembler']
        )


rule tax_class_kraken2_workflow:
    '''
    kraken2 workflow
    '''
    input:
        expand( kraken2_ouput,
                sample    = sample_input_files,
                qual      = workflows['tax_class_kraken2_workflow']['qual'],
                direction = directions,
                db        = workflows['tax_class_kraken2_workflow']['db'],
                conf      = workflows['tax_class_kraken2_workflow']['confidence'],
        )


rule tax_class_krakenuniq_workflow:
    '''
    krakenuniq workflow
    '''
    input:
        expand( krakenuniq_ouput,
                sample    = sample_input_files,
                qual      = workflows['tax_class_krakenuniq_workflow']['qual'],
                direction = directions,
                db        = workflows['tax_class_krakenuniq_workflow']['db'],
                hll_prec  = workflows['tax_class_krakenuniq_workflow']['hll_precision'],
        )


rule tax_class_bracken_workflow:
    input:
        expand( bracken_output,
            sample      = sample_input_files,
            bdb         = workflows['tax_class_bracken_workflow']['bdb'],
            read_length = workflows['tax_class_bracken_workflow']['read_length'],
            level       = workflows['tax_class_bracken_workflow']['level'],
            threshold   = workflows['tax_class_bracken_workflow']['threshold'],
            qual        = workflows['tax_class_kraken2_workflow']['qual'],
            db          = workflows['tax_class_kraken2_workflow']['db'],
            conf        = workflows['tax_class_kraken2_workflow']['confidence'],
        )


rule tax_class_mash_dist_workflow:
    '''
    mash takes uncompressed interleaved files as input
    '''
    input:
        expand( mash_dist_sort_output,
            sample      = sample_input_files,
            qual        = workflows['tax_class_mash_dist_workflow']['qual'],
            db          = workflows['tax_class_mash_dist_workflow']['mash_db'],
        )

rule tax_class_mash_screen_workflow:
    '''
    mash takes uncompressed interleaved files as input
    '''
    input:
        expand( mash_screen_sort_output,
            sample      = sample_input_files,
            qual        = workflows['tax_class_mash_screen_workflow']['qual'],
            db          = workflows['tax_class_mash_screen_workflow']['mash_db'],
        )
#TODO: FIX, doesn't work
rule tax_class_prep_mtsv_db:
    input:
      mtsv_db  
